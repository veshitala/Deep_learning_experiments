{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Importnat_Code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veshitala/Deep_learning_experiments/blob/master/Importnat_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4gUUl6XIjs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lapCFdTZIkKL",
        "colab_type": "text"
      },
      "source": [
        "HOW **add Google drive into colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H_ovy1FIart",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Start by connecting gdrive into the google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEbvLrnJBUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g-H4QCLJKR0",
        "colab_type": "text"
      },
      "source": [
        "**How to download the required packages to save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqG8XCj2I0Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install h5py pyyaml\n",
        "!pip install tf_nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EUcBP1I1W_",
        "colab_type": "text"
      },
      "source": [
        "# How to save your model in h5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wv9dj-0Ip7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wypk6RltJZl1",
        "colab_type": "text"
      },
      "source": [
        "**How to load a saved model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWoKUl42Jdey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from keras.models import load_model\n",
        "classifierLoad = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5nQ1ZpXJemJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H20gCRwyKIO6",
        "colab_type": "text"
      },
      "source": [
        "# How to check and upload images to test your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV7JOxyCKPCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes)\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a notmonkey\")\n",
        "  else:\n",
        "    print(fn + \" is a monkey\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tv--GN5KQ95",
        "colab_type": "text"
      },
      "source": [
        "# How to give path during saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkO06bcfNjXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'transfer.h5'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCxksWjtmc4",
        "colab_type": "text"
      },
      "source": [
        "# Wtaching how your images are being transformed through each layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxLD0A9NkAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "# Let's prepare a random input image from the training set.\n",
        "\"\"\"monkey_img_files = [os.path.join(train_monkey_dir, f) for f in train_monkey_names]\n",
        "notmonkey_img_files = [os.path.join(train_notmonkey_dir, f) for f in train_notmonkey_names]\n",
        "img_path = random.choice(monkey_img_files + notmonkey_img_files)\"\"\"\n",
        "img_path = F\"/content/monkey.25.jpg\"\n",
        "img = load_img(img_path, target_size=(300, 300))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}